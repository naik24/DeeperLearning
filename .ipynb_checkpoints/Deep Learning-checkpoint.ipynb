{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcd55c6d",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc952075",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "To define deep learning and understand the difference between deep learning and other machine learning approaches, first we need some idea of what machine learning algorithms do. To perform machine learning, we need 3 things:\n",
    "\n",
    "- Input data points\n",
    "- Examples of expected output\n",
    "- Measure of Performance\n",
    "\n",
    "A machine learning model transforms its input data into meaningful outputs, a process that is learned from exposure to known examples of inputs and outputs. Therefore, the central problem in machine learning and deep learning is to meaningfully transform data: in other words, to learn useful representations of the input data at hand. But what is a representation? At its core, it's a different way to look at data - to represent or encode data. For instance, a color image can be encoded in the RGB format or in the HSV format: these are two representations of the same data. Machine learning models are all about finding appropriate representations for their input data - transformations of the data that make it more amenable to the task at hand, such as a classification task.\n",
    "\n",
    "*Machine learning is technically: searching for useful representations of some input data, within a predefined space of possibilities, using guidance from a feedback signal.*\n",
    "\n",
    "**1.1 Deep Learning**\n",
    "Deep Learning is a new take on learning representations from data that puts an emphasis on learning successive layers of increasing meaningful representations.The number of layers contributing to the model define the *depth* of the model. The layered representations are learned via models called neural networks, structured in literal layers stacked on top of each other. \n",
    "\n",
    "*Deep Learning is technically: a multistage way to learn data representations.*\n",
    "\n",
    "**1.1.1 Understanding how Deep Learning works**\n",
    "The specification of what a layer does to its input data is stored in the layer's *weights*, which in essence are a bunch of numbers. In technical terms, we'd say that the transformation implemented by a layer is *parameterized* by its weights. In this context, learning means finding a set of values for the weights of all layers in a network, such that the network will map example inputs to their associated targets. \n",
    "\n",
    "To control a neural network, you need to be able to measure how far this output is from what we expected. This is done by a *loss function*, also called as *objective function*. The loss function takes the predictions of the network and the true target and computes a distance score. \n",
    "\n",
    "The fundamental trick in deep learning is to use this score as a feedback signal to adjust the value of the weights a little, in a direction that will lower the loss score for the current example. This adjustment is done by an *optimizer*, which implements what's called the *backprop* algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089e4172",
   "metadata": {},
   "source": [
    "## 2. Fundamentals of Machine Learning\n",
    "\n",
    "**2.1 Training, validation, and test sets**\n",
    "\n",
    "**2.1.1 Simple Hold-Out Validation** Set apart some fraction of your data as your test set. Train on the remaining data, and evaluate on the test set. This is the simplest evaluation protocol, and it suffers from one flaw: if little data is available, then your validation and test sets may contain too few samples. \n",
    "\n",
    "**2.1.2 K-Fold Validation** With this approach, you split your data into K partitions of equal size. For each partition i, train a model on the remaining K - 1 partitions, and evaluate it on partition i. Your final score is then the averages of the K scores obtained. \n",
    "\n",
    "**2.1.3 Iterated K-Fold Validation with Shuffling** This one is for situations in which you have relatively little data available and you need to evaluate your model as precisely as possible. It consists of applying K-fold validation multiple times, shuffling the data every time before splitting it K ways. \n",
    "\n",
    "**2.2 Data Preprocessing, Feature Engineering, and Feature Learning**\n",
    "\n",
    "**2.2.1 Data Preprocessing for Neural Networks** Data preprocessing aims at making the raw data at hand more amenable to neural networks. This includes vectorization, normalization, handling missing values, and feature extraction.\n",
    "\n",
    "**Vectorization** All inputs and targets in a neural network must be tensors of floating-point data. Whatever data we need to process - sound, images, text - you must first turn into tensors, a step called data vectorization. \n",
    "\n",
    "**Value Normalization** To make learning easier for your network, your data should have the following characteristics:\n",
    "- Take small values - Typically, most values should be in the range 0 - 1\n",
    "- Be homogeneous - All features should take values in roughly the same range\n",
    "- Each feature should be normalized independently to have a mean of 0 and standard deviation of 1\n",
    "\n",
    "**2.2.2 Feature Engineering** is the process of using your own knowledge about the data and about machine learning algorithm at hand to make the algorithm work better by applying hardcoded (nonlearned) transformations to the data before it goes into the model. \n",
    "\n",
    "**2.3 Overfitting and Underfitting**\n",
    "\n",
    "The fundamental issue in machine learning is the tension between optimization and generalization. Optimization refers to the process of adjusting a model to get the best performance possible on the training data whereas generalization refers to how well the trained model performs on data it has never seen before. \n",
    "\n",
    "At the beginning of training, optimization and generalization are correlated: the lower the loss on training data, the lower the loss on test data. While this is happening, the model is said to underfit: there is still progress to be made; the network hasn't yet modeled all relevant patterns in the training data. But after a certain number of iterations on the training data, generalization stops improving, and validation metrics stall and begin to degrade: the model is staring to overfit. It's beginning to learn patterns that are specific to the training data but are misleading or irrelevant when it comes to new data. \n",
    "\n",
    "To prevent a model from learning misleading or irrelevant patterns found in the training data, the best solution is to get more training data. When that isn't possible, the next-best solution is to modulate the quantity of information that your model is allowed to store or to add constraints on what information it's allowed to store. If a network can only afford to memorize a small number of patterns, the optimization process will force it to focus on the most prominent patterns, which have a better chance of generalizing well. The process of fighting overfitting this way is called regularization.\n",
    "\n",
    "**2.3.1 Reducing the network's size** This is the simplest way of reduce overfitting. In deep learning, the number of learnable paramters in a model is often referred to as the model's capacity. A model with more paramters has more memorization capacity and therefore can easily learn a perfect dictionary-like mapping between training samples and their targets - a mapping without any generalization power. If the network has limited memorization resources, it won't be able to learn this mapping as easily; thus, in order to minimize its loss, it will have to resort to learning compressed representations that have predictive power regarding the targets - precisely the type of representations we are interested in. \n",
    "\n",
    "**2.3.2 Adding Weight Regularization** The principle of Occam's razor states that given two explanations for something, the explanation most likely to be correct is the simplest one - the one that makes fewer assumptions. The idea also applies to neural networks. Simpler models are less likely to overfit than complex ones. A simples model in this context is a model where the distribution of parameter values has less entropy. Thus, a common way to mitigate overfitting is to put constraints on the complexity of a network by forcing its weights to take only small values, which makes the distribution of weight values more regular. This is called weight regularization, and it's done by adding to the loss function of the network a cost associated with having large weights. This cost comes in two flavors:\n",
    "- L1 regularization: The cost added is proportional to the absolute value of the weight coefficient\n",
    "- L2 regularization: The cost added is proportional to the square of the value of the weight coefficient. L2 is also called weight decay in the context of neural networks. \n",
    "\n",
    "**2.3.3 Adding Dropout** Dropout, applied to a layer, consists of randomly dropping out a number of output features of the layer during training. The dropout rate is the fraction of features that are zeroed out; it's usually set between 0.2 and 0.5. \n",
    "\n",
    "**2.4 Universal Workflow of Machine Learning**\n",
    "\n",
    "**2.4.1 Defining the problem and assembling a dataset** First, you must define the problem at hand:\n",
    "- What will your input data be? What are you trying to predict? You can only learn to predict something if you have available training data.\n",
    "- What type of problem are you facing? Is it binary classification? Is it multiclass classification? Identifying the problem type will guide your choice of model architecture, loss function, and so on.\n",
    "\n",
    "You can't move to the next stage until you know what your inputs and outpus are, and what data you'll use. Be aware of the hypotheses you make at this stage:\n",
    "- You hypothesize that your outputs can be predicted given your inputs\n",
    "- You hypothesize that your available data is sufficiently informative to learn the relationship between inputs and outputs. \n",
    "\n",
    "**2.4.2 Choosing a measure of success** Your metric for success will guide the choice of a loss function: what your model will optimize. For balanced classification problems, where every class is equally likely, accuracy and area under the receiver operating characteristic curve (ROC AUC) are common metrics. For class-imbalanced problems, you can use precision and recall. For ranking problems or multilabel classification, you can use mean average precision. \n",
    "\n",
    "**2.4.3 Deciding on an evaluation protocol** Once you know what you're aiming for, you must establish how you'll measure your current progress. The three common evaluation protocols are: \n",
    "- Maintaining a hold-out validation set\n",
    "- Doing K-fold cross validation\n",
    "- Doing iterated K-fold validation\n",
    "\n",
    "**2.4.4 Preparing your data** \n",
    "- Your data should be formatted as tensors\n",
    "- The values taken by these tensors should be usually be scaled to small values\n",
    "- Data should be normalized\n",
    "- Feature engineering\n",
    "\n",
    "**2.4.5 Developing a model that is better than a baseline** You need to make three key choices to build your first working model:\n",
    "- Last layer activation \n",
    "- Loss Function\n",
    "- Optimization configuration\n",
    "\n",
    "**2.4.6 Developing a model that overfits** \n",
    "- Add layers\n",
    "- Make the layers bigger\n",
    "- Train for more epochs\n",
    "\n",
    "**2.4.7 Regularizing your model and tuning your hyperparamters**\n",
    "- Add dropout\n",
    "- Try different architectures: add or remove layers\n",
    "- Add L1 / L2\n",
    "- Try different hyperparameters to find optimal configuration\n",
    "- Optionally, iterate on feature engineering: add new features, or remove features that don't seem informative\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fe7ae5",
   "metadata": {},
   "source": [
    "## 3. Deep Learning for Computer Vision\n",
    "\n",
    "**3.1 Convnets**\n",
    "\n",
    "A convnet takes as input tensors of shape (image_height, image_width, image_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1714a313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 16ms/step - loss: nan - accuracy: 0.1063\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: nan - accuracy: 0.0987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x157b71310>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation = \"relu\", input_shape = (28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation = \"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation = \"relu\"))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation = \"relu\"))\n",
    "model.add(layers.Dense(10, activation = \"relu\"))\n",
    "\n",
    "model.compile(optimizer = \"rmsprop\",\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = [\"accuracy\"])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs = 5, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20996cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.799999743700027"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "test_acc * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270cf466",
   "metadata": {},
   "source": [
    "**3.2 The convolution Operation**\n",
    "\n",
    "The fundamental difference between a densely connected layer and a convolution layer is this: Dense layers learn global patterns in their input feature space, whereas convolution layers learn local patterns: in case of images, patterns found in small 2D windows of the inputs. \n",
    "\n",
    "This key characteristic gives convnets two interesting properties:\n",
    "- The patterns they learn are translation invariant: After learning a certain a pattern in the lower-right corner of a picture, a convnet can recognize it anywhere: for example in the upper left corner. \n",
    "- They can learn spatial hierarchies of patterns: A first convolutional layer will learn small local patterns such as edges, a second conv layer will leran larger patterns made of features of the first layers, and so on. \n",
    "\n",
    "Convolutions operate over 3D tensors, called feature maps, with two spatial axes(height and width) as well as a depth axis (also called as channel axis). The convolution operation extracts pathes from its input feature map and applies the same transformation to all of these patches, producing an output feature map.\n",
    "\n",
    "Convolutions are defined by two key paramters:\n",
    "- Size of the patches extracted from the inputs\n",
    "- Depth of the output feature map\n",
    "\n",
    "**Max Pooling** consists of extracting windows from the input feature maps and outputting the max value of each filter. Pooling is used to reduce the number of feature-map coefficients to process, as well as to induce spatial-filter hierarchies by making successive convolution layers look at increasingly large windows. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
